#!/usr/bin/env python3
"""
AI ë¹„ì „ ë¶„ì„ ë…¸ë“œ - ArUco ë§ˆì»¤ + YOLO ì¥ì• ë¬¼ ê°ì§€
ì„œë²„(192.168.0.3)ì—ì„œ ì‹¤í–‰
"""
from __future__ import annotations
import json
import os
import time
from dataclasses import dataclass
from datetime import datetime
from typing import Optional

import cv2
import numpy as np
import requests
import rclpy
from rclpy.node import Node
from std_msgs.msg import String

from .config import ROS, MQTT

# Optional imports
try:
    import paho.mqtt.client as mqtt
    MQTT_OK = True
except ImportError:
    MQTT_OK = False

try:
    from ultralytics import YOLO
    YOLO_OK = True
except ImportError:
    YOLO_OK = False

try:
    import cv2.aruco as aruco
    ARUCO_OK = True
except ImportError:
    ARUCO_OK = False


@dataclass
class Detection:
    """ê°ì§€ ê²°ê³¼"""
    cls: str
    confidence: float
    bbox: list
    center: list


class AIVisionAnalyzer(Node):
    """ArUco + YOLO ë¹„ì „ ë¶„ì„ ë…¸ë“œ"""
    
    # YOLO í´ë˜ìŠ¤ â†’ ì¥ì• ë¬¼ íƒ€ì… ë§¤í•‘
    CLASS_TO_OBSTACLE = {
        'PORT_A': 'obstacle_at_PORT_A',
        'PORT_B': 'obstacle_at_PORT_B',
    }
    
    def __init__(self):
        super().__init__('ai_vision_analyzer')
        
        # íŒŒë¼ë¯¸í„°
        p = self._declare_params()
        self.camera_url = f"http://{p['robot_ip']}:{p['robot_port']}/image.jpg"
        self.model_path = p['model_path']
        self.confidence = p['confidence']
        self.save_images = p['save_images']
        self.save_path = p['save_path']
        self.mode = p['mode']  # slam ë˜ëŠ” nav2
        
        # ìƒíƒœ
        self.model: Optional[YOLO] = None
        self.model_ok = False
        self.aruco_detector = None
        self.mqtt_client = None
        self.analysis_count = 0
        self.saved_aruco = set()
        self.saved_obstacles = set()
        
        # ì´ˆê¸°í™”
        if ARUCO_OK:
            self._init_aruco()
        if YOLO_OK:
            self._load_model()
        if MQTT_OK:
            self._init_mqtt(p['mqtt_host'], p['mqtt_port'])
        
        # ì €ì¥ í´ë” ìƒì„± (ëª¨ë“œë³„ êµ¬ë¶„)
        if self.save_images:
            os.makedirs(os.path.join(self.save_path, 'aruco'), exist_ok=True)
            os.makedirs(os.path.join(self.save_path, 'obstacles'), exist_ok=True)
            os.makedirs(os.path.join(self.save_path, 'nav2_obstacles'), exist_ok=True)
            self.get_logger().info(f"ğŸ“ ì €ì¥ í´ë”: {self.save_path} (ëª¨ë“œ: {self.mode})")
        
        # ROS2 í¼ë¸”ë¦¬ì…”
        self.pub_aruco = self.create_publisher(String, ROS.AI_ARUCO, 10)
        self.pub_obstacle = self.create_publisher(String, ROS.AI_OBSTACLE, 10)
        
        # íƒ€ì´ë¨¸
        self.create_timer(1.0 / p['analysis_fps'], self._analyze)
        self.create_timer(10.0, self._log_status)
        
        self.get_logger().info(f"AI Vision ì‹œì‘: ArUco={'âœ…' if self.aruco_detector else 'âŒ'}, "
                               f"YOLO={'âœ…' if self.model_ok else 'âŒ'}")
    
    def _declare_params(self) -> dict:
        """íŒŒë¼ë¯¸í„° ì„ ì–¸"""
        params = {
            'robot_ip': '192.168.0.5', 'robot_port': 5200,
            'model_path': '/home/kim1/model/best.pt', 'confidence': 0.5,
            'analysis_fps': 1.0, 'mqtt_host': 'localhost', 'mqtt_port': 1883,
            'save_images': True, 'save_path': '/home/kim1/save/ai_detections',
            'mode': 'slam',  # 'slam' ë˜ëŠ” 'nav2'
        }
        for name, default in params.items():
            self.declare_parameter(name, default)
            params[name] = self.get_parameter(name).value
        return params
    
    def _init_aruco(self):
        try:
            aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_4X4_50)
            self.aruco_detector = cv2.aruco.ArucoDetector(aruco_dict, cv2.aruco.DetectorParameters())
        except Exception as e:
            self.get_logger().error(f"ArUco ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def _load_model(self):
        try:
            self.model = YOLO(self.model_path)
            self.model_ok = True
        except Exception as e:
            self.get_logger().error(f"YOLO ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def _init_mqtt(self, host: str, port: int):
        try:
            self.mqtt_client = mqtt.Client()
            self.mqtt_client.connect_async(host, port, 60)
            self.mqtt_client.loop_start()
        except Exception as e:
            self.get_logger().error(f"MQTT ì—°ê²° ì‹¤íŒ¨: {e}")
    
    def _analyze(self):
        try:
            image = self._fetch_image()
            if image is None:
                return
            self.analysis_count += 1
            
            if self.aruco_detector:
                markers = self._detect_aruco(image)
                if markers:
                    self._publish_aruco(markers)
                    self._save_aruco_image(image, markers)
            
            if self.model_ok:
                obstacles = self._detect_obstacles(image)
                if obstacles:
                    self._publish_obstacles(obstacles)
                    self._save_obstacle_image(image, obstacles)
        except Exception as e:
            self.get_logger().error(f"ë¶„ì„ ì˜¤ë¥˜: {e}")
    
    def _fetch_image(self) -> Optional[np.ndarray]:
        try:
            resp = requests.get(self.camera_url, timeout=2)
            if resp.status_code == 200:
                return cv2.imdecode(np.frombuffer(resp.content, np.uint8), cv2.IMREAD_COLOR)
        except requests.RequestException:
            pass
        return None
    
    def _detect_aruco(self, image: np.ndarray) -> list:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        corners, ids, _ = self.aruco_detector.detectMarkers(gray)
        if ids is None:
            return []
        markers = []
        for i, mid in enumerate(ids):
            corner = corners[i][0]
            cx, cy = int(np.mean(corner[:, 0])), int(np.mean(corner[:, 1]))
            markers.append({'id': int(mid[0]), 'corners': corner.tolist(), 'center': [cx, cy]})
            self.get_logger().info(f"ArUco #{mid[0]} @ ({cx}, {cy})")
        return markers
    
    def _detect_obstacles(self, image: np.ndarray) -> list:
        """YOLOë¡œ ì¥ì• ë¬¼ ê°ì§€ (PORT_A/B â†’ obstacle_at_PORT_A/B)"""
        try:
            results = self.model.predict(image, conf=self.confidence, verbose=False)
            obstacles = []
            for r in results:
                for box in r.boxes:
                    cls_name = self.model.names[int(box.cls[0])]
                    # í´ë˜ìŠ¤ â†’ ì¥ì• ë¬¼ íƒ€ì… ë§¤í•‘
                    obstacle_type = self.CLASS_TO_OBSTACLE.get(cls_name)
                    if obstacle_type:
                        x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())
                        conf = float(box.conf[0])
                        obstacles.append(Detection(
                            cls=obstacle_type, 
                            confidence=conf,
                            bbox=[x1, y1, x2, y2], 
                            center=[(x1+x2)//2, (y1+y2)//2]
                        ))
                        self.get_logger().warn(f"ğŸš§ ì¥ì• ë¬¼ ê°ì§€: {obstacle_type} (conf: {conf:.2f}) @ ({(x1+x2)//2}, {(y1+y2)//2})")
            return obstacles
        except Exception as e:
            self.get_logger().error(f"YOLO ì˜¤ë¥˜: {e}")
            return []
    
    def _publish_aruco(self, markers: list):
        data = {'timestamp': datetime.now().isoformat(), 'markers': markers}
        self.pub_aruco.publish(String(data=json.dumps(data)))
        if self.mqtt_client:
            self.mqtt_client.publish(MQTT.AI_ARUCO, json.dumps({'markers': markers, 'timestamp': time.time()}), qos=1)
    
    def _publish_obstacles(self, obstacles: list):
        """ì¥ì• ë¬¼ ì •ë³´ ë°œí–‰ (ROS2 í† í”½ + MQTT)"""
        obs_list = [{'type': o.cls, 'confidence': o.confidence, 'bbox': o.bbox, 'center': o.center} for o in obstacles]
        timestamp_str = datetime.now().isoformat()
        
        # ROS2 í† í”½ ë°œí–‰
        data = {'timestamp': timestamp_str, 'count': len(obstacles), 'obstacles': obs_list}
        self.pub_obstacle.publish(String(data=json.dumps(data)))
        
        # MQTT ë°œí–‰
        if self.mqtt_client:
            mqtt_data = {
                'timestamp': time.time(),
                'timestamp_str': timestamp_str,
                'count': len(obstacles),
                'obstacles': obs_list,
                'summary': [f"{o.cls}({o.confidence:.1%})" for o in obstacles]
            }
            self.mqtt_client.publish(MQTT.AI_OBSTACLE, json.dumps(mqtt_data), qos=1)
        
        # ì½˜ì†” ë¡œê·¸
        self.get_logger().info(f"ğŸš§ ì¥ì• ë¬¼ {len(obstacles)}ê°œ ë°œí–‰: {', '.join([o.cls for o in obstacles])}")
    
    def _save_aruco_image(self, image: np.ndarray, markers: list):
        if not self.save_images:
            return
        for m in markers:
            mid = m['id']
            if mid in self.saved_aruco:
                continue
            self.saved_aruco.add(mid)
            img = image.copy()
            cv2.polylines(img, [np.array(m['corners'], dtype=np.int32)], True, (0, 255, 0), 3)
            cv2.putText(img, f"#{mid}", tuple(m['center']), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), 2)
            ts = datetime.now().strftime('%Y%m%d_%H%M%S')
            cv2.imwrite(os.path.join(self.save_path, 'aruco', f"aruco_{mid}_{ts}.jpg"), img)
    
    def _save_obstacle_image(self, image: np.ndarray, obstacles: list):
        """ì¥ì• ë¬¼ ë°œê²¬ ì‹œ ë§¤ë²ˆ ì‚¬ì§„ ì €ì¥ ë° ë¡œê·¸ ë°œí–‰ (ëª¨ë“œë³„ í´ë” êµ¬ë¶„)"""
        if not self.save_images:
            return
        
        # ëª¨ë“œì— ë”°ë¼ ì €ì¥ í´ë” ì„ íƒ
        if self.mode == 'nav2':
            save_folder = 'nav2_obstacles'
            mode_emoji = 'ğŸ§­'
        else:
            save_folder = 'obstacles'
            mode_emoji = 'ğŸ—ºï¸'
        
        for o in obstacles:
            img = image.copy()
            # ë°”ìš´ë”© ë°•ìŠ¤ì™€ ë ˆì´ë¸” ê·¸ë¦¬ê¸°
            cv2.rectangle(img, (o.bbox[0], o.bbox[1]), (o.bbox[2], o.bbox[3]), (0, 0, 255), 3)
            label = f"{o.cls} ({o.confidence:.2f})"
            cv2.putText(img, label, (o.bbox[0], o.bbox[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 2)
            
            # ëª¨ë“œ í‘œì‹œ ì¶”ê°€
            cv2.putText(img, f"Mode: {self.mode.upper()}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 0), 2)
            
            # íƒ€ì„ìŠ¤íƒ¬í”„ë¡œ íŒŒì¼ëª… ìƒì„± (ë§¤ë²ˆ ìƒˆë¡œìš´ íŒŒì¼)
            ts = datetime.now().strftime('%Y%m%d_%H%M%S_%f')
            filename = f"{o.cls}_{ts}.jpg"
            filepath = os.path.join(self.save_path, save_folder, filename)
            cv2.imwrite(filepath, img)
            
            # ìƒì„¸ ë¡œê·¸ (ëª¨ë“œ ì •ë³´ í¬í•¨)
            self.get_logger().info(f"{mode_emoji} [{self.mode.upper()}] ğŸ“¸ ì¥ì• ë¬¼ ì‚¬ì§„ ì €ì¥: {save_folder}/{filename}")
            self.get_logger().warn(f"âš ï¸ [{self.mode.upper()}] ì¥ì• ë¬¼ ë°œê²¬! íƒ€ì…: {o.cls}, ì‹ ë¢°ë„: {o.confidence:.2%}, "
                                   f"ìœ„ì¹˜: ì¤‘ì‹¬({o.center[0]}, {o.center[1]}), "
                                   f"ì˜ì—­: ({o.bbox[0]}, {o.bbox[1]}) ~ ({o.bbox[2]}, {o.bbox[3]})")
            
            # ì €ì¥ëœ ì¥ì• ë¬¼ íƒ€ì… ê¸°ë¡ (í†µê³„ìš©)
            self.saved_obstacles.add(o.cls)
    
    def _log_status(self):
        self.get_logger().info(f"ë¶„ì„: {self.analysis_count}íšŒ, ArUco: {len(self.saved_aruco)}, ì¥ì• ë¬¼: {len(self.saved_obstacles)}")
    
    def destroy_node(self):
        if self.mqtt_client:
            try:
                self.mqtt_client.loop_stop()
                self.mqtt_client.disconnect()
            except:
                pass
        super().destroy_node()


def main(args=None):
    rclpy.init(args=args)
    if not YOLO_OK:
        print("âŒ ultralytics í•„ìš”: pip install ultralytics")
        return
    node = AIVisionAnalyzer()
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    finally:
        node.destroy_node()
        if rclpy.ok():
            rclpy.shutdown()


if __name__ == '__main__':
    main()
